import { NextRequest, NextResponse } from 'next/server';

export async function POST(request: NextRequest) {
  try {
    console.log('üìù VLM Inference API called');
    
    const { video_url, threshold } = await request.json();
    console.log('üì• Request data:', { video_url: video_url?.substring(0, 100) + '...', threshold });

    if (!video_url) {
      console.log('‚ùå No video URL provided');
      return NextResponse.json({ error: 'Video URL is required' }, { status: 400 });
    }

    console.log('üé• Fetching video from URL...');
    // Fetch the video file from the URL
    const videoResponse = await fetch(video_url);
    if (!videoResponse.ok) {
      console.log('‚ùå Failed to fetch video:', videoResponse.statusText);
      throw new Error(`Failed to fetch video: ${videoResponse.statusText}`);
    }

    console.log('‚úÖ Video fetched successfully, converting to blob...');
    const videoBlob = await videoResponse.blob();
    console.log('üìä Video blob size:', videoBlob.size, 'bytes');

    // Create FormData for the external API (only video file)
    const formData = new FormData();
    formData.append('video', videoBlob, 'node_video.mp4');
    
    // Threshold should be a query parameter
    const thresholdValue = threshold?.toString() || '0.5';
    const apiUrl = `http://127.0.0.1:8001/vlm-inference-comparison/?threshold=${thresholdValue}`;
    
    console.log('üöÄ Calling VLM inference API with threshold:', thresholdValue);
    // Call the VLM inference API
    const apiResponse = await fetch(apiUrl, {
      method: 'POST',
      body: formData,
    });

    console.log('üì° VLM API response status:', apiResponse.status);
    if (!apiResponse.ok) {
      const errorText = await apiResponse.text();
      console.log('‚ùå VLM API error response:', errorText);
      throw new Error(`API request failed: ${apiResponse.statusText} - ${errorText}`);
    }

    const result = await apiResponse.json();
    console.log('‚úÖ VLM API success:', result);
    return NextResponse.json(result);

  } catch (error) {
    console.error('üí• VLM Inference API Error:', error);
    return NextResponse.json(
      { 
        error: 'Failed to process VLM inference request',
        details: error instanceof Error ? error.message : 'Unknown error'
      },
      { status: 500 }
    );
  }
}